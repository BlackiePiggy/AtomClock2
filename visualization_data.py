"""
åŸå­é’Ÿé¥æµ‹æ•°æ®å®Œæ•´å¯è§†åŒ–è„šæœ¬
åŠ è½½pickleæ–‡ä»¶å¹¶åŸºäºçœŸå®timestampå±•ç¤º
"""

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from datetime import datetime, timedelta
import pickle
from pathlib import Path

from config import FILE_PATHS

# è®¾ç½®ä¸­æ–‡æ˜¾ç¤º
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# ç»Ÿä¸€ä¸­æ–‡æ–‡æœ¬ä½¿ç”¨çš„å­—ä½“ï¼ˆç”¨äºé¿å…ç¼ºå¤±å­—å½¢è­¦å‘Šï¼‰
TEXT_FONT_KWARGS = {
    'fontfamily': plt.rcParams['font.sans-serif'][0]
} if plt.rcParams.get('font.sans-serif') else {}


def load_pickle(filepath):
    """åŠ è½½pickleæ–‡ä»¶"""
    with open(filepath, 'rb') as f:
        return pickle.load(f)


def create_timestamps(unit_data, start_datetime='2024-01-01 00:00:00', sampling_interval=10):
    """
    æ ¹æ®unit_dataçš„timestampså­—æ®µç”ŸæˆçœŸå®çš„datetimeå¯¹è±¡

    å‚æ•°:
        unit_data: å•å…ƒæ•°æ®å­—å…¸
        start_datetime: èµ·å§‹æ—¶é—´å­—ç¬¦ä¸²
        sampling_interval: é‡‡æ ·é—´éš”ï¼ˆç§’ï¼‰

    è¿”å›:
        æ‰€æœ‰æ•°æ®ç‚¹å¯¹åº”çš„datetimeåˆ—è¡¨
    """
    start_dt = datetime.strptime(start_datetime, '%Y-%m-%d %H:%M:%S')

    all_datetimes = []
    for seg_idx, timestamps in enumerate(unit_data['timestamps']):
        # timestampsæ˜¯è¯¥æ®µæ¯ä¸ªç‚¹çš„å…¨å±€æ—¶é—´æ­¥
        seg_datetimes = [start_dt + timedelta(seconds=int(t * sampling_interval))
                         for t in timestamps]
        all_datetimes.extend(seg_datetimes)

    return all_datetimes


def prepare_unit_sequence(unit_data, start_datetime, sampling_interval):
    """å°†å•å…ƒçš„æ‰€æœ‰ç‰‡æ®µæ‹¼æ¥æˆè¿ç»­åºåˆ—åŠå¯¹åº”çš„æ—¶é—´æˆ³"""

    if unit_data is None:
        return None, None

    segments = np.vstack(unit_data['segments'])
    datetimes = create_timestamps(unit_data, start_datetime, sampling_interval)
    return segments, datetimes


def compute_channel_statistics(sequence):
    """è®¡ç®—æ¯ä¸ªé€šé“çš„ç»Ÿè®¡é‡"""

    if sequence is None:
        return []

    stats = []
    for ch in range(sequence.shape[1]):
        channel_data = sequence[:, ch]
        stats.append({
            'min': float(np.min(channel_data)),
            'max': float(np.max(channel_data)),
            'mean': float(np.mean(channel_data)),
            'std': float(np.std(channel_data)),
            'median': float(np.median(channel_data)),
            'p05': float(np.percentile(channel_data, 5)),
            'p95': float(np.percentile(channel_data, 95)),
        })
    return stats


def format_stats_text(channel_idx, stats):
    """æ ¼å¼åŒ–é€šé“ç»Ÿè®¡ä¿¡æ¯æ–‡æœ¬"""

    return (
        f"é€šé“{channel_idx}\n"
        f"  min: {stats['min']:.4f}\n"
        f"  max: {stats['max']:.4f}\n"
        f"  mean: {stats['mean']:.4f}\n"
        f"  std: {stats['std']:.4f}\n"
        f"  median: {stats['median']:.4f}\n"
        f"  p05-p95: [{stats['p05']:.4f}, {stats['p95']:.4f}]"
    )


def build_dataset_summary(unit_id, unit_data, datetimes, stats):
    """ç”Ÿæˆæ•°æ®é›†çš„æ–‡æœ¬æ‘˜è¦"""

    if unit_data is None or datetimes is None:
        return "æ— æ•°æ®å¯å±•ç¤º"

    duration_hours = (datetimes[-1] - datetimes[0]).total_seconds() / 3600
    n_points = len(datetimes)
    n_channels = len(stats)
    n_segments = len(unit_data['segments'])

    drift_rate = unit_data.get('drift_rate', 0.0)
    noise_level = unit_data.get('noise_level', 0.0)
    trend_pattern = unit_data.get('trend_pattern', 'unknown')

    summary_lines = [
        f"ã€å•å…ƒ {unit_id} æ•°æ®æ‘˜è¦ã€‘",
        "",
        f"æ•°æ®ç‚¹æ•°: {n_points:,}",
        f"é€šé“æ•°: {n_channels}",
        f"åˆ†æ®µæ•°: {n_segments}",
        f"èµ·å§‹æ—¶é—´: {datetimes[0].strftime('%Y-%m-%d %H:%M:%S')}",
        f"ç»“æŸæ—¶é—´: {datetimes[-1].strftime('%Y-%m-%d %H:%M:%S')}",
        f"æ€»æ—¶é•¿: {duration_hours:.2f} å°æ—¶",
        "",
        f"è¶‹åŠ¿æ¨¡å¼: {trend_pattern}",
        f"æ¼‚ç§»ç‡: {drift_rate:.6f}",
        f"å™ªå£°æ°´å¹³: {noise_level:.4f}",
        "",
        "æ¯é€šé“å‡å€¼èŒƒå›´:",
    ]

    for idx, channel_stats in enumerate(stats):
        summary_lines.append(
            f"  é€šé“{idx}: mean={channel_stats['mean']:.4f} Â± {channel_stats['std']:.4f}"
        )

    return "\n".join(summary_lines)


def plot_channel_timeseries(ax, datetimes, sequence, channel_idx, stats, title, color):
    """ç»˜åˆ¶å•ä¸ªé€šé“çš„æ—¶é—´åºåˆ—"""

    if sequence is None or datetimes is None:
        ax.text(0.5, 0.5, 'æ— æ•°æ®', ha='center', va='center', fontsize=12, color='gray')
        ax.axis('off')
        return

    downsample = max(1, len(datetimes) // 6000)
    times = datetimes[::downsample]
    values = sequence[::downsample, channel_idx]

    ax.plot(times, values, color=color, linewidth=1.0, alpha=0.8)
    ax.axhline(stats['mean'], color=color, linestyle='--', linewidth=1, alpha=0.9,
               label='å‡å€¼')
    ax.axhline(stats['mean'] + stats['std'], color=color, linestyle=':', linewidth=0.8,
               alpha=0.6)
    ax.axhline(stats['mean'] - stats['std'], color=color, linestyle=':', linewidth=0.8,
               alpha=0.6)

    ax.set_title(title, fontsize=12, fontweight='bold')
    ax.set_ylabel('å¹…å€¼', fontsize=10)
    ax.grid(True, alpha=0.25, linestyle='--')
    ax.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d %H:%M'))
    plt.setp(ax.xaxis.get_majorticklabels(), rotation=25, ha='right', fontsize=8)

    stats_text = format_stats_text(channel_idx, stats)
    ax.text(0.99, 0.95, stats_text,
            transform=ax.transAxes,
            ha='right', va='top',
            fontsize=8,
            **TEXT_FONT_KWARGS,
            bbox=dict(boxstyle='round', facecolor='white', alpha=0.85, edgecolor=color))

def visualize_complete_telemetry_data(normal_data_path, anomaly_data_path,
                                     output_dir='figures',
                                     start_datetime='2024-01-01 00:00:00',
                                     sampling_interval=10,
                                     normal_unit_id=None,
                                     anomaly_unit_id=None,
                                     output_path=None):
    """
    å®Œæ•´å¯è§†åŒ–åŸå­é’Ÿé¥æµ‹æ•°æ®ï¼ˆåŸºäºçœŸå®timestampï¼‰

    å‚æ•°:
        normal_data_path: æ­£å¸¸å•å…ƒæ•°æ®pickleæ–‡ä»¶è·¯å¾„
        anomaly_data_path: å¼‚å¸¸å•å…ƒæ•°æ®pickleæ–‡ä»¶è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•
        start_datetime: èµ·å§‹æ—¶é—´
        sampling_interval: é‡‡æ ·é—´éš”ï¼ˆç§’ï¼‰
    """

    # åˆ›å»ºè¾“å‡ºç›®å½•
    Path(output_dir).mkdir(parents=True, exist_ok=True)

    print("="*80)
    print("åŸå­é’Ÿé¥æµ‹æ•°æ®å®Œæ•´å¯è§†åŒ–")
    print("="*80)

    # 1. åŠ è½½æ•°æ®
    print(f"\n[1/4] åŠ è½½æ•°æ®...")
    print(f"  æ­£å¸¸å•å…ƒæ•°æ®: {normal_data_path}")
    print(f"  å¼‚å¸¸å•å…ƒæ•°æ®: {anomaly_data_path}")

    normal_data = load_pickle(normal_data_path)
    anomaly_data = load_pickle(anomaly_data_path) if Path(anomaly_data_path).exists() else {}

    print(f"  âœ“ æˆåŠŸåŠ è½½ {len(normal_data)} ä¸ªæ­£å¸¸å•å…ƒ")
    print(f"  âœ“ æˆåŠŸåŠ è½½ {len(anomaly_data)} ä¸ªå¼‚å¸¸å•å…ƒ")

    # 2. é€‰æ‹©å±•ç¤ºçš„å•å…ƒ
    normal_units = list(normal_data.keys())
    anomaly_units = list(anomaly_data.keys())

    if len(normal_units) == 0:
        print("  âœ— é”™è¯¯ï¼šæ²¡æœ‰æ­£å¸¸å•å…ƒæ•°æ®ï¼")
        return

    # é€‰æ‹©è¦å±•ç¤ºçš„æ­£å¸¸å•å…ƒ
    if normal_unit_id and normal_unit_id in normal_data:
        selected_normal_id = normal_unit_id
    else:
        selected_normal_id = normal_units[0]
    selected_normal_unit = normal_data[selected_normal_id]

    print(f"\n[2/4] å¤„ç†æ•°æ®...")
    print(f"  é€‰æ‹©å•å…ƒ: {selected_normal_id}")
    print(f"  è¶‹åŠ¿æ¨¡å¼: {selected_normal_unit.get('trend_pattern', 'unknown')}")
    print(f"  æ¼‚ç§»ç‡: {selected_normal_unit.get('drift_rate', 0):.6f}")
    print(f"  å™ªå£°æ°´å¹³: {selected_normal_unit.get('noise_level', 0):.4f}")

    # åˆå¹¶æ‰€æœ‰æ®µ
    all_segments = np.vstack(selected_normal_unit['segments'])
    all_datetimes = create_timestamps(selected_normal_unit, start_datetime, sampling_interval)

    n_points = len(all_datetimes)
    n_channels = all_segments.shape[1]
    time_span = (all_datetimes[-1] - all_datetimes[0]).total_seconds() / 3600  # å°æ—¶

    print(f"  æ•°æ®ç‚¹æ•°: {n_points:,}")
    print(f"  é€šé“æ•°: {n_channels}")
    print(f"  æ—¶é—´èŒƒå›´: {all_datetimes[0]} ~ {all_datetimes[-1]}")
    print(f"  æ€»æ—¶é•¿: {time_span:.2f} å°æ—¶ ({time_span/24:.2f} å¤©)")

    # 3. åˆ›å»ºå¯è§†åŒ–
    print(f"\n[3/4] ç”Ÿæˆå¯è§†åŒ–...")

    fig = plt.figure(figsize=(20, 16))
    gs = fig.add_gridspec(5, 2, hspace=0.35, wspace=0.25)

    # é¢œè‰²æ–¹æ¡ˆ
    colors = ['#ef4444', '#f59e0b', '#10b981', '#3b82f6', '#8b5cf6', '#ec4899', '#06b6d4']

    # ==================== 1. å®Œæ•´æ—¶é—´åºåˆ—ï¼ˆå•é€šé“ï¼‰====================
    print("  - ç»˜åˆ¶å®Œæ•´æ—¶é—´åºåˆ—...")
    ax1 = fig.add_subplot(gs[0, :])
    channel_idx = 0

    ax1.plot(all_datetimes, all_segments[:, channel_idx],
             'b-', linewidth=0.5, alpha=0.7, label=f'é€šé“{channel_idx}')

    ax1.set_xlabel('æ—¶é—´', fontsize=12, fontweight='bold')
    ax1.set_ylabel('å¹…å€¼', fontsize=12, fontweight='bold')
    ax1.set_title(f'å®Œæ•´æ—¶é—´åºåˆ— - {selected_normal_id} (é€šé“{channel_idx})\n'
                  f'è¶‹åŠ¿: {selected_normal_unit.get("trend_pattern", "unknown")} | '
                  f'æ€»æ—¶é•¿: {time_span:.1f}å°æ—¶ | æ•°æ®ç‚¹: {n_points:,}',
                  fontsize=14, fontweight='bold', pad=15)
    ax1.grid(True, alpha=0.3, linestyle='--')
    ax1.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d %H:%M'))
    plt.setp(ax1.xaxis.get_majorticklabels(), rotation=30, ha='right')

    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
    ch0_data = all_segments[:, channel_idx]
    mean_val = np.mean(ch0_data)
    std_val = np.std(ch0_data)
    min_val = np.min(ch0_data)
    max_val = np.max(ch0_data)

    stats_text = f'å‡å€¼: {mean_val:.4f}\næ ‡å‡†å·®: {std_val:.4f}\nå€¼åŸŸ: [{min_val:.4f}, {max_val:.4f}]'
    ax1.text(0.02, 0.98, stats_text,
             transform=ax1.transAxes, verticalalignment='top',
             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.85),
             fontsize=10,
             **TEXT_FONT_KWARGS)

    # ==================== 2. å±€éƒ¨æ”¾å¤§ï¼ˆæ˜¾ç¤ºå™ªå£°ï¼‰====================
    print("  - ç»˜åˆ¶å±€éƒ¨æ”¾å¤§å›¾...")
    ax2 = fig.add_subplot(gs[1, 0])

    zoom_start = len(all_datetimes) // 2
    zoom_end = zoom_start + 1000

    ax2.plot(all_datetimes[zoom_start:zoom_end],
             all_segments[zoom_start:zoom_end, channel_idx],
             'b-', linewidth=1.2)

    ax2.set_xlabel('æ—¶é—´', fontsize=11)
    ax2.set_ylabel('å¹…å€¼', fontsize=11)
    ax2.set_title('å±€éƒ¨æ”¾å¤§ - æ˜¾ç¤ºé«˜é¢‘å™ªå£°ç‰¹å¾ï¼ˆæ— å‘¨æœŸï¼‰', fontsize=12, fontweight='bold')
    ax2.grid(True, alpha=0.3)
    ax2.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))
    plt.setp(ax2.xaxis.get_majorticklabels(), rotation=30, ha='right', fontsize=9)

    # ==================== 3. è¶‹åŠ¿æå–ï¼ˆæ»‘åŠ¨å¹³å‡ï¼‰====================
    print("  - è¿›è¡Œè¶‹åŠ¿æå–...")
    ax3 = fig.add_subplot(gs[1, 1])

    window = 500
    smoothed = np.convolve(ch0_data, np.ones(window)/window, mode='valid')
    smoothed_times = all_datetimes[:len(smoothed)]

    ax3.plot(all_datetimes, ch0_data,
             color='lightblue', linewidth=0.3, alpha=0.4, label='åŸå§‹æ•°æ®')
    ax3.plot(smoothed_times, smoothed,
             'r-', linewidth=2.5, label=f'å¹³æ»‘è¶‹åŠ¿(çª—å£={window})')

    ax3.set_xlabel('æ—¶é—´', fontsize=11)
    ax3.set_ylabel('å¹…å€¼', fontsize=11)
    ax3.set_title('è¶‹åŠ¿æå– - æ»‘åŠ¨å¹³å‡å»å™ªæ˜¾ç¤ºçº¯å•è°ƒç‰¹å¾', fontsize=12, fontweight='bold')
    ax3.legend(loc='best', fontsize=10)
    ax3.grid(True, alpha=0.3)
    ax3.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d %H:%M'))
    plt.setp(ax3.xaxis.get_majorticklabels(), rotation=30, ha='right', fontsize=9)

    # ==================== 4. å¤šé€šé“å¯¹æ¯” ====================
    print("  - ç»˜åˆ¶å¤šé€šé“å¯¹æ¯”...")
    ax4 = fig.add_subplot(gs[2, :])

    n_channels_display = min(5, n_channels)
    downsample = max(1, len(all_datetimes) // 5000)  # é™é‡‡æ ·

    for ch in range(n_channels_display):
        ax4.plot(all_datetimes[::downsample],
                all_segments[::downsample, ch],
                alpha=0.7, linewidth=1.5,
                label=f'é€šé“{ch}',
                color=colors[ch % len(colors)])

    ax4.set_xlabel('æ—¶é—´', fontsize=12, fontweight='bold')
    ax4.set_ylabel('å¹…å€¼', fontsize=12, fontweight='bold')
    ax4.set_title('å¤šé€šé“å¯¹æ¯” - ä¸åŒé€šé“çš„å•è°ƒè¶‹åŠ¿æ¨¡å¼', fontsize=14, fontweight='bold')
    ax4.legend(loc='best', fontsize=10, ncol=n_channels_display)
    ax4.grid(True, alpha=0.3)
    ax4.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d %H:%M'))
    plt.setp(ax4.xaxis.get_majorticklabels(), rotation=30, ha='right')

    # ==================== 5. åˆ†æ®µç»Ÿè®¡ ====================
    print("  - è®¡ç®—åˆ†æ®µç»Ÿè®¡...")
    ax5 = fig.add_subplot(gs[3, 0])

    n_segments = len(selected_normal_unit['segments'])
    segment_means = []
    segment_stds = []
    segment_labels = []

    for seg_idx, segment in enumerate(selected_normal_unit['segments']):
        seg_data = segment[:, channel_idx]
        segment_means.append(np.mean(seg_data))
        segment_stds.append(np.std(seg_data))
        segment_labels.append(f'S{seg_idx+1}')

    # åªæ˜¾ç¤ºå‰20ä¸ªæ®µï¼ˆé¿å…è¿‡äºæ‹¥æŒ¤ï¼‰
    display_segments = min(20, n_segments)
    x_pos = np.arange(display_segments)
    width = 0.35

    ax5_twin = ax5.twinx()
    ax5.bar(x_pos - width/2, segment_means[:display_segments], width,
            label='å‡å€¼', color='#8b5cf6', alpha=0.8)
    ax5_twin.bar(x_pos + width/2, segment_stds[:display_segments], width,
                 label='æ ‡å‡†å·®', color='#06b6d4', alpha=0.8)

    ax5.set_xlabel('æ•°æ®æ®µ', fontsize=11)
    ax5.set_ylabel('å‡å€¼', fontsize=11, color='#8b5cf6', fontweight='bold')
    ax5_twin.set_ylabel('æ ‡å‡†å·®', fontsize=11, color='#06b6d4', fontweight='bold')
    ax5.set_title(f'åˆ†æ®µç»Ÿè®¡ - å„æ®µå‡å€¼ä¸æ ‡å‡†å·® (å‰{display_segments}æ®µ)',
                  fontsize=12, fontweight='bold')
    ax5.set_xticks(x_pos)
    ax5.set_xticklabels(segment_labels[:display_segments], fontsize=8, rotation=45)
    ax5.tick_params(axis='y', labelcolor='#8b5cf6')
    ax5_twin.tick_params(axis='y', labelcolor='#06b6d4')
    ax5.grid(True, alpha=0.3, axis='y')

    # ==================== 6. è¶‹åŠ¿å˜åŒ–ç‡ ====================
    print("  - åˆ†æè¶‹åŠ¿å˜åŒ–ç‡...")
    ax6 = fig.add_subplot(gs[3, 1])

    segment_trends = []
    for segment in selected_normal_unit['segments'][:display_segments]:
        seg_data = segment[:, channel_idx]
        trend_rate = (seg_data[-1] - seg_data[0]) / len(seg_data)
        segment_trends.append(trend_rate)

    colors_bar = ['green' if t > 0 else 'red' for t in segment_trends]
    ax6.bar(segment_labels[:display_segments], segment_trends,
            color=colors_bar, alpha=0.7, edgecolor='black', linewidth=0.5)
    ax6.axhline(y=0, color='black', linestyle='--', linewidth=2)

    ax6.set_xlabel('æ•°æ®æ®µ', fontsize=11)
    ax6.set_ylabel('è¶‹åŠ¿å˜åŒ–ç‡', fontsize=11)
    ax6.set_title(f'è¶‹åŠ¿å˜åŒ–ç‡åˆ†æ (å‰{display_segments}æ®µ)', fontsize=12, fontweight='bold')
    ax6.grid(True, alpha=0.3, axis='y')
    plt.setp(ax6.xaxis.get_majorticklabels(), rotation=45, fontsize=8)

    positive_count = sum(1 for t in segment_trends if t > 0)
    negative_count = sum(1 for t in segment_trends if t < 0)
    ax6.text(0.98, 0.98,
             f'ä¸Šå‡: {positive_count}/{len(segment_trends)}\n'
             f'ä¸‹é™: {negative_count}/{len(segment_trends)}',
             transform=ax6.transAxes, verticalalignment='top', horizontalalignment='right',
             bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.9),
             fontsize=9)

    # ==================== 7. æ­£å¸¸vså¼‚å¸¸å¯¹æ¯” ====================
    print("  - ç»˜åˆ¶æ­£å¸¸vså¼‚å¸¸å¯¹æ¯”...")
    ax7 = fig.add_subplot(gs[4, 0])

    if len(anomaly_units) > 0:
        if anomaly_unit_id and anomaly_unit_id in anomaly_data:
            selected_anomaly_id = anomaly_unit_id
        else:
            selected_anomaly_id = anomaly_units[0]
        selected_anomaly_unit = anomaly_data[selected_anomaly_id]

        anomaly_segments = np.vstack(selected_anomaly_unit['segments'])
        anomaly_datetimes = create_timestamps(selected_anomaly_unit, start_datetime, sampling_interval)

        # å¹³æ»‘å¤„ç†
        normal_smooth = np.convolve(ch0_data, np.ones(window)/window, mode='valid')
        anomaly_smooth = np.convolve(anomaly_segments[:, channel_idx],
                                     np.ones(window)/window, mode='valid')

        normal_smooth_times = all_datetimes[:len(normal_smooth)]
        anomaly_smooth_times = anomaly_datetimes[:len(anomaly_smooth)]

        ax7.plot(normal_smooth_times, normal_smooth,
                'b-', linewidth=2, alpha=0.7, label='æ­£å¸¸')
        ax7.plot(anomaly_smooth_times, anomaly_smooth,
                'r-', linewidth=2, alpha=0.7,
                label=f'å¼‚å¸¸({selected_anomaly_unit.get("anomaly_type", "unknown")})')

        ax7.set_xlabel('æ—¶é—´', fontsize=11)
        ax7.set_ylabel('å¹…å€¼ï¼ˆå¹³æ»‘ï¼‰', fontsize=11)
        ax7.set_title(f'æ­£å¸¸ vs å¼‚å¸¸ è¶‹åŠ¿å¯¹æ¯”\n'
                     f'æ­£å¸¸: {selected_normal_unit.get("trend_pattern", "?")} | '
                     f'å¼‚å¸¸: {selected_anomaly_unit.get("trend_pattern", "?")}',
                     fontsize=12, fontweight='bold')
        ax7.legend(loc='best', fontsize=10)
        ax7.grid(True, alpha=0.3)
        ax7.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d %H:%M'))
        plt.setp(ax7.xaxis.get_majorticklabels(), rotation=30, ha='right', fontsize=9)
    else:
        ax7.text(0.5, 0.5, 'æ— å¼‚å¸¸æ•°æ®',
                ha='center', va='center', fontsize=16, color='gray')
        ax7.set_xlim(0, 1)
        ax7.set_ylim(0, 1)
        ax7.axis('off')

    # ==================== 8. æ•°æ®ç‰¹å¾æ€»ç»“ ====================
    print("  - ç”Ÿæˆæ•°æ®ç‰¹å¾æ€»ç»“...")
    ax8 = fig.add_subplot(gs[4, 1])
    ax8.axis('off')

    sampling_rate = n_points / time_span  # ç‚¹/å°æ—¶

    summary_text = f"""
ã€åŸå­é’Ÿé¥æµ‹æ•°æ®ç‰¹å¾æ€»ç»“ã€‘

ğŸ“Š åŸºæœ¬ä¿¡æ¯
  â€¢ å•å…ƒID: {selected_normal_id}
  â€¢ æ•°æ®ç‚¹æ•°: {n_points:,} ç‚¹
  â€¢ é€šé“æ•°: {n_channels} ä¸ª
  â€¢ åˆ†æ®µæ•°: {n_segments} æ®µ

â± æ—¶é—´ç‰¹å¾
  â€¢ èµ·å§‹æ—¶é—´: {all_datetimes[0].strftime('%Y-%m-%d %H:%M:%S')}
  â€¢ ç»“æŸæ—¶é—´: {all_datetimes[-1].strftime('%Y-%m-%d %H:%M:%S')}
  â€¢ æ€»æ—¶é•¿: {time_span:.2f} å°æ—¶ ({time_span/24:.2f} å¤©)
  â€¢ é‡‡æ ·ç‡: ~{sampling_rate:.1f} ç‚¹/å°æ—¶
  â€¢ é‡‡æ ·é—´éš”: {sampling_interval} ç§’/ç‚¹

ğŸ“ˆ ä¿¡å·ç‰¹å¾
  â€¢ è¶‹åŠ¿æ¨¡å¼: {selected_normal_unit.get('trend_pattern', 'unknown')}
  â€¢ æ¼‚ç§»ç‡: {selected_normal_unit.get('drift_rate', 0):.6f}
  â€¢ å™ªå£°æ°´å¹³: {selected_normal_unit.get('noise_level', 0):.4f}
  â€¢ ä¿¡å™ªæ¯”: {abs(mean_val/std_val):.2f}

ğŸ” æ•°æ®è´¨é‡ (é€šé“{channel_idx})
  â€¢ å€¼åŸŸ: [{min_val:.4f}, {max_val:.4f}]
  â€¢ å‡å€¼: {mean_val:.4f}
  â€¢ æ ‡å‡†å·®: {std_val:.4f}
  â€¢ ä¸Šå‡æ®µ: {positive_count}/{len(segment_trends)} ({positive_count/len(segment_trends)*100:.1f}%)
  â€¢ ä¸‹é™æ®µ: {negative_count}/{len(segment_trends)} ({negative_count/len(segment_trends)*100:.1f}%)

ğŸ“¦ æ•°æ®é›†è§„æ¨¡
  â€¢ æ­£å¸¸å•å…ƒ: {len(normal_data)} ä¸ª
  â€¢ å¼‚å¸¸å•å…ƒ: {len(anomaly_data)} ä¸ª
    """

    ax8.text(0.05, 0.95, summary_text,
            transform=ax8.transAxes,
            verticalalignment='top',
            fontsize=9.5,
            **TEXT_FONT_KWARGS,
            bbox=dict(boxstyle='round', facecolor='#f0f9ff',
                     alpha=0.95, edgecolor='#3b82f6', linewidth=2.5))

    # æ€»æ ‡é¢˜
    fig.suptitle('åŸå­é’Ÿé¥æµ‹æ•°æ®å®Œæ•´å±•ç¤º - åŸºäºçœŸå®Timestampçš„è¿ç»­æ—¶é—´è½´',
                fontsize=18, fontweight='bold', y=0.995)

    # ä¿å­˜å›¾ç‰‡
    print(f"\n[4/4] ä¿å­˜å¯è§†åŒ–...")
    if output_path is None:
        output_path = Path(output_dir) / 'telemetry_data_complete_visualization.png'
    else:
        output_path = Path(output_path)

    output_path.parent.mkdir(parents=True, exist_ok=True)
    plt.savefig(output_path, dpi=300, bbox_inches='tight', facecolor='white')
    print(f"  âœ“ å·²ä¿å­˜è‡³: {output_path}")

    print("\n" + "="*80)
    print("âœ“ å¯è§†åŒ–å®Œæˆï¼")
    print("="*80)

    plt.show()


def visualize_channel_feature_overview(normal_data_path, anomaly_data_path,
                                       start_datetime='2024-01-01 00:00:00',
                                       sampling_interval=10,
                                       normal_unit_id=None,
                                       anomaly_unit_id=None,
                                       output_path=None):
    """å¯¹æ¯”å±•ç¤ºæ­£å¸¸ä¸å¼‚å¸¸å•å…ƒçš„å…¨éƒ¨é€šé“ç‰¹å¾"""

    print("=" * 80)
    print("åŸå­é’Ÿé¥æµ‹æ•°æ®é€šé“ç‰¹å¾æ€»è§ˆ")
    print("=" * 80)

    print(f"\n[1/3] åŠ è½½æ•°æ®...")
    print(f"  æ­£å¸¸æ•°æ®: {normal_data_path}")
    print(f"  å¼‚å¸¸æ•°æ®: {anomaly_data_path}")

    normal_data = load_pickle(normal_data_path)
    anomaly_data = load_pickle(anomaly_data_path) if Path(anomaly_data_path).exists() else {}

    normal_units = list(normal_data.keys())
    anomaly_units = list(anomaly_data.keys())

    if not normal_units:
        print("  âœ— é”™è¯¯ï¼šæ— æ­£å¸¸å•å…ƒæ•°æ®ï¼")
        return

    if normal_unit_id and normal_unit_id in normal_data:
        selected_normal_id = normal_unit_id
    else:
        selected_normal_id = normal_units[0]

    selected_normal_unit = normal_data[selected_normal_id]
    normal_sequence, normal_datetimes = prepare_unit_sequence(
        selected_normal_unit, start_datetime, sampling_interval)
    normal_stats = compute_channel_statistics(normal_sequence)

    if anomaly_units:
        if anomaly_unit_id and anomaly_unit_id in anomaly_data:
            selected_anomaly_id = anomaly_unit_id
        else:
            selected_anomaly_id = anomaly_units[0]

        selected_anomaly_unit = anomaly_data[selected_anomaly_id]
        anomaly_sequence, anomaly_datetimes = prepare_unit_sequence(
            selected_anomaly_unit, start_datetime, sampling_interval)
        anomaly_stats = compute_channel_statistics(anomaly_sequence)
    else:
        selected_anomaly_id = None
        selected_anomaly_unit = None
        anomaly_sequence = None
        anomaly_datetimes = None
        anomaly_stats = []

    n_channels = 0
    if normal_sequence is not None:
        n_channels = normal_sequence.shape[1]
    elif anomaly_sequence is not None:
        n_channels = anomaly_sequence.shape[1]

    if n_channels == 0:
        print("  âœ— é”™è¯¯ï¼šæ— å¯ç”¨äºå±•ç¤ºçš„é€šé“æ•°æ®ï¼")
        return

    print(f"\n[2/3] ç”Ÿæˆå¯è§†åŒ–... (å…± {n_channels} ä¸ªé€šé“)")

    colors = ['#ef4444', '#f59e0b', '#10b981', '#3b82f6', '#8b5cf6', '#ec4899', '#06b6d4']

    fig = plt.figure(figsize=(22, 3 * n_channels + 4))
    gs = fig.add_gridspec(n_channels + 1, 2,
                          height_ratios=[3] * n_channels + [1.6],
                          hspace=0.4, wspace=0.25)

    for ch in range(n_channels):
        color = colors[ch % len(colors)]

        ax_normal = fig.add_subplot(gs[ch, 0])
        title_normal = f'æ­£å¸¸é€šé“{ch} - å•å…ƒ {selected_normal_id}'
        if normal_sequence is not None:
            plot_channel_timeseries(
                ax_normal,
                normal_datetimes,
                normal_sequence,
                ch,
                normal_stats[ch],
                title_normal,
                color,
            )
        else:
            ax_normal.text(0.5, 0.5, 'æ— æ­£å¸¸æ•°æ®', ha='center', va='center',
                           fontsize=12, color='gray')
            ax_normal.axis('off')

        ax_anomaly = fig.add_subplot(gs[ch, 1])
        if anomaly_sequence is not None and ch < anomaly_sequence.shape[1]:
            title_anomaly = (
                f'å¼‚å¸¸é€šé“{ch} - å•å…ƒ {selected_anomaly_id} '
                f"({selected_anomaly_unit.get('anomaly_type', 'unknown')})"
            )
            plot_channel_timeseries(
                ax_anomaly,
                anomaly_datetimes,
                anomaly_sequence,
                ch,
                anomaly_stats[ch],
                title_anomaly,
                color,
            )
        else:
            ax_anomaly.text(0.5, 0.5, 'æ— å¼‚å¸¸æ•°æ®', ha='center', va='center',
                            fontsize=12, color='gray')
            ax_anomaly.axis('off')

    ax_summary_normal = fig.add_subplot(gs[-1, 0])
    ax_summary_normal.axis('off')
    normal_summary = build_dataset_summary(
        selected_normal_id, selected_normal_unit, normal_datetimes, normal_stats)
    ax_summary_normal.text(
        0.02, 0.95, normal_summary,
        transform=ax_summary_normal.transAxes,
        va='top', ha='left', fontsize=10,
        **TEXT_FONT_KWARGS,
        bbox=dict(boxstyle='round', facecolor='#f1f5f9',
                  edgecolor='#1d4ed8', linewidth=2, alpha=0.95)
    )

    ax_summary_anomaly = fig.add_subplot(gs[-1, 1])
    ax_summary_anomaly.axis('off')
    anomaly_summary = build_dataset_summary(
        selected_anomaly_id, selected_anomaly_unit, anomaly_datetimes, anomaly_stats)
    ax_summary_anomaly.text(
        0.02, 0.95, anomaly_summary,
        transform=ax_summary_anomaly.transAxes,
        va='top', ha='left', fontsize=10,
        **TEXT_FONT_KWARGS,
        bbox=dict(boxstyle='round', facecolor='#fef3c7',
                  edgecolor='#b45309', linewidth=2, alpha=0.95)
    )

    fig.suptitle('æ­£å¸¸ vs å¼‚å¸¸ å•å…ƒé€šé“ç‰¹å¾æ¦‚è§ˆ', fontsize=18, fontweight='bold', y=0.995)
    plt.tight_layout(rect=[0, 0, 1, 0.98])

    print(f"\n[3/3] ä¿å­˜å›¾åƒ...")
    if output_path is None:
        output_path = FILE_PATHS.get(
            'channel_overview_visualization',
            Path('figures') / 'telemetry_channel_overview.png'
        )

    output_path = Path(output_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    plt.savefig(output_path, dpi=300, bbox_inches='tight', facecolor='white')
    print(f"  âœ“ å·²ä¿å­˜è‡³: {output_path}")

    print("\n" + "=" * 80)
    print("âœ“ é€šé“ç‰¹å¾å¯è§†åŒ–å®Œæˆï¼")
    print("=" * 80)

    plt.show()


def main():
    """ä¸»å‡½æ•°"""

    # æ–‡ä»¶è·¯å¾„
    normal_data_path = FILE_PATHS['raw_normal_data']
    anomaly_data_path = FILE_PATHS['raw_anomaly_data']
    output_dir = Path(FILE_PATHS['data_visualization']).parent

    # æ—¶é—´å‚æ•°
    start_datetime = '2024-01-01 00:00:00'
    sampling_interval = 10  # ç§’

    # æ‰§è¡Œå¯è§†åŒ–
    visualize_complete_telemetry_data(
        normal_data_path=normal_data_path,
        anomaly_data_path=anomaly_data_path,
        output_dir=output_dir,
        start_datetime=start_datetime,
        sampling_interval=sampling_interval
    )

    visualize_channel_feature_overview(
        normal_data_path=normal_data_path,
        anomaly_data_path=anomaly_data_path,
        start_datetime=start_datetime,
        sampling_interval=sampling_interval
    )


if __name__ == "__main__":
    main()
